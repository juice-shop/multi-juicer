# Default values for Wrongecret-ctf-party.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

imagePullPolicy: IfNotPresent
nodeSelector: {}

ingress:
  # -- If true, Wrongsecrets will create an Ingress object for the balancer service.
  # Useful if you want to expose the balancer service externally for example with a loadbalancer in order to view any webpages that are hosted on the balancer service.
  enabled: false
  # -- Annotations to be added to the ingress object.
  annotations: {}
  # kubernetes.io/ingress.class: nginx
  # kubernetes.io/tls-acme: "true"
  # -- Hostnames to your Wrongsecrets balancer installation.
  hosts:
    - host: wrongsecrets-ctf-party.local
      paths:
        - "/"
  # -- TLS configuration for Wrongsecrets balancer
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

service:
  type: ClusterIP
  port: 3000

balancer:
  cookie:
    # SET THIS TO TRUE IF IN PRODUCTION
    # Sets secure Flag in cookie
    # -- Sets the secure attribute on cookie so that it only be send over https
    secure: false
    # -- Changes the cookies name used to identify teams. Note will automatically be prefixed with "__Secure-" when balancer.cookie.secure is set to `true`
    name: balancer
    # -- Set this to a fixed random alpa-numeric string (recommended length 24 chars). If not set this get randomly generated with every helm upgrade, each rotation invalidates all active cookies / sessions requirering users to login again.
    cookieParserSecret: null
  repository: jeroenwillemsen/wrongsecrets-balancer
  tag: 1.6.6aws
  # -- Number of replicas of the wrongsecrets-balancer deployment. Changing this in a commit? PLEASE UPDATE THE GITHUB WORKLFOWS THEN!(NUMBER OF "TRUE")
  replicas: 2
  # -- Port to expose on the balancer pods which the container listens on
  containerPort: 3000
  service:
    # -- Kubernetes service type
    type: ClusterIP
    # -- internal cluster service IP
    clusterIP: null
    # -- IP address to assign to load balancer (if supported)
    loadBalancerIP: null
    # -- list of IP CIDRs allowed access to lb (if supported)
    loadBalancerSourceRanges: null
    # -- IP address to assign to load balancer (if supported)
    externalIPs: null
  # -- Probes settings for the balancer pods
  # -- livenessProbe: Checks if the balancer pod is still alive
  livenessProbe:
    httpGet:
      path: /balancer/
      port: http # -- Port to expose on the balancer pods which the container listens on. It is named http to be the same as the containerPort
  # -- readinessProbe: Checks if the balancer pod is ready to receive traffic
  readinessProbe:
    httpGet:
      path: /balancer/
      port: http # -- Port to expose on the balancer pods which the container listens on. It is named http to be the same as the containerPort
  # -- Resource limits and requests for the balancer pods
  resources:
    requests:
      memory: 256Mi
      cpu: 400m
    limits:
      memory: 1024Mi
      cpu: 1000m
  # -- Optional Configure kubernetes scheduling affinity for the created wrongsecrets instances (see: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)
  affinity: {}
  # -- Optional Configure kubernetes toleration for the created wrongsecrets instances (see: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
  tolerations: []
  # -- If set to true this skips setting ownerReferences on the teams wrongsecrets Deployment and Services. This lets MultiJuicer run in older kubernetes cluster which don't support the reference type or the app/v1 deployment type
  skipOwnerReference: false
  env:
    REACT_APP_MOVING_GIF_LOGO: "https://i.gifer.com/9kGQ.gif" #displayed at the frontend when you enter the CTF
    REACT_APP_HEROKU_WRONGSECRETS_URL: "https://wrongsecrets-ctf.herokuapp.com" #required for 3 domain setup
    REACT_APP_CTFD_URL: "https://ctfd.io" #requierd for 2 and 3 domain setup
    REACT_APP_S3_BUCKET_URL: "s3://funstuff" #the s3 bucket you use for teh aws challenges, don't forget to make it accessible!
    K8S_ENV: "k8s" #or 'aws'
    REACT_APP_ACCESS_PASSWORD: "" #DEFAULT NO PASSWORD, PLAYING THIS IN PUBLIC? PUT A FANCY STRING HERE, BUT BE GENTLE: USERS NEED TO BE ABLE TO COPY THAT STUFF...
    REACT_APP_CREATE_TEAM_HMAC_KEY: "hardcodedkey"
    IRSA_ROLE: arn:aws:iam::233483431651:role/wrongsecrets-secret-manager #change this in your own AWS role!
    SECRETS_MANAGER_SECRET_ID_1: "wrongsecret" #only change if you need non-default AWS SM entries
    SECRETS_MANAGER_SECRET_ID_2: "wrongsecret-2" #only change if you need non-default AWS SM entries
    CHALLENGE33_VALUE: "VkJVR2gzd3UvM0kxbmFIajFVZjk3WTBMcThCNS85MnExandwMy9hWVN3SFNKSThXcWRabllMajc4aEVTbGZQUEtmMVpLUGFwNHoyK3IrRzlOUndkRlUvWUJNVFkzY05ndU1tNUM2bDJwVEs5SmhQRm5VemVySXdNcm5odTlHanJxU0ZuL0J0T3ZMblFhL21TZ1hETkpZVU9VOGdDSEZzOUpFZVF2OWhwV3B5eGxCMk5xdTBNSHJQTk9EWTNab2hoa2pXWGF4YmpDWmk5U3BtSHlkVTA2WjdMcVd5RjM5RzZWOENGNkxCUGtkVW4zYUpBVisrRjBROUljU009Cg=="
  metrics:
    # -- enables prometheus metrics for the balancer. If set to true you should change the prometheus-scraper password
    enabled: true
    dashboards:
      # -- if true, creates a Grafana Dashboard Config Map. (also requires metrics.enabled to be true). These will automatically be imported by Grafana when using the Grafana helm chart, see: https://github.com/helm/charts/tree/main/stable/grafana#sidecar-for-dashboards
      enabled: false
    serviceMonitor:
      # -- If true, creates a Prometheus Operator ServiceMonitor (also requires metrics.enabled to be true). This will also deploy a servicemonitor which monitors metrics from the Juice Shop instances
      enabled: false
    basicAuth:
      username: prometheus-scraper
      # -- Should be changed when metrics are enabled.
      password: ERzCT4pwBDxfCKRGmfrMa8KQ8sXf8GKy
  podSecurityContext:
    # -- If true, sets the securityContext on the created pods. This is required for the podSecurityPolicy to work
    enabled: true
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    seccompProfile:
      type: RuntimeDefault
  containerSecurityContext:
    # -- If true, sets the securityContext on the created containers. This is required for the podSecurityPolicy to work
    enabled: true
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    capabilities:
      drop:
        - ALL
      add:
        - CAP_NET_ADMIN
        - CAP_NET_BIND_SERVICE
    seccompProfile:
      type: RuntimeDefault
  volumeMounts:
    # -- If true, creates a volumeMount for the created pods. This is required for the podSecurityPolicy to work
    - name: config-volume
      mountPath: /home/app/config/
  volumes:
    # -- If true, creates a volume for the created pods. This is required for the podSecurityPolicy to work
    - name: config-volume
      configMap:
        name: wrongsecrets-balancer-config

wrongsecrets:
  # -- Specifies how many Wrongsecrets instances should start at max. Set to -1 to remove the max Wrongsecrets instance cap
  maxInstances: 500
  # -- Wrongsecrets Image to use
  image: jeroenwillemsen/wrongsecrets
  tag: 1.6.7RC1-no-vault
  # -- Change the key when hosting a CTF event. This key gets used to generate the challenge flags. See: https://github.com/OWASP/wrongsecrets#ctf
  ctfKey: "zLp@.-6fMW6L-7R3b!9uR_K!NfkkTr"
  # -- Specify a custom Wrongsecrets config.yaml. See the Wrongsecrets Docs for any needed ENVs: https://github.com/OWASP/wrongsecrets
  # @default -- See values.yaml for full details
  config: |
    K8S_ENV: aws
  # "aws" is for using the cluster with eks and "k8s" is for using the cluster with miniKube which will enable specific challenges
  # -- Specify a custom NODE_ENV for Wrongsecrets. If value is changed to something other than 'wrongsecrets-ctf-party' it's not possible to set a custom config via `wrongsecrets-balancer-config`.
  nodeEnv: "wrongsecrets-ctf-party"
  # -- Optional resources definitions to set for each Wrongsecrets instance
  resources:
    requests:
      cpu: 256Mi
      memory: 300Mi
  #  limits:
  #    cpu: 100m
  #    memory: 200Mi
  # -- Optional securityContext definitions to set for each Wrongsecrets instance
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    capabilities:
      drop:
        - ALL
    seccompProfile:
      type: RuntimeDefault
  # -- Optional environment variables to set for each Wrongsecrets instance (see: https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/)
  env:
    - name: K8S_ENV
      value: k8s
    - name: SPECIAL_K8S_SECRET
      valueFrom:
        configMapKeyRef:
          name: secrets-file
          key: funny.entry
    - name: SPECIAL_SPECIAL_K8S_SECRET
      valueFrom:
        secretKeyRef:
          name: funnystuff
          key: funnier
  # -- Optional mount environment variables from configMaps or secrets (see: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables)
  envFrom: []
  # -- Optional Volumes to set for each Wrongsecrets instance (see: https://kubernetes.io/docs/concepts/storage/volumes/)
  volumes: []
  # -- Optional Configure kubernetes scheduling affinity for the created Wrongsecrets instances (see: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)
  affinity: {}
  # -- Optional Configure kubernetes toleration for the created Wrongsecrets instances (see: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
  tolerations: []

  # -- Optional Can be used to configure the runtime class for the Wrongsecrets instances pods to add an additional layer of isolation to reduce the impact of potential container escapes. (see: https://kubernetes.io/docs/concepts/containers/runtime-class/)
  runtimeClassName: null

# Deletes unused Wrongsecrets instances after a configurable period of inactivity

#the virtual desktop for the deploymebt
virtualdesktop:
  # -- Specifies how many Wrongsecrets instances MultiJuicer should start at max. Set to -1 to remove the max Juice Shop instance cap
  maxInstances: 500
  # -- Juice Shop Image to use
  image: jeroenwillemsen/wrongsecrets-desktop-k8s
  tag: 1.6.6
  repository: commjoenie/wrongSecrets
  resources:
    request:
      memory: 1GB
      cpu: 50m
    limits:
      memory: 2GB
      cpu: 1200m
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    capabilities:
      drop:
        - ALL
    seccompProfile:
      type: RuntimeDefault
  runtimeClassName: {}
  affinity: {}
  # -- Optional mount environment variables from configMaps or secrets (see: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables)

  envFrom: []
  tolerations: []

## preps for the vault container: see https://github.com/OWASP/wrongsecrets-ctf-party/issues/250
vaultContainer:
  # -- Specifies how many JuiceShop instances MultiJuicer should start at max. Set to -1 to remove the max Juice Shop instance cap
  maxInstances: 500
  # -- Juice Shop Image to use
  image: hashicorp/vault
  tag: 1.15.1
  repository: commjoenie/wrongSecrets
  resources:
    request:
      memory: 128mb
      cpu: 50m
    limits:
      memory: 256mb
      cpu: 1200m
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    capabilities:
      drop:
        - ALL
    seccompProfile:
      type: RuntimeDefault
  runtimeClassName: {}
  affinity: {}
  # -- Optional mount environment variables from configMaps or secrets (see: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables)

  envFrom: []
  tolerations: []



# Deletes unused Wrongsecrets namespaces after a configurable period of inactivity
wrongsecretsCleanup:
  repository: jeroenwillemsen/wrongsecrets-ctf-cleaner
  tag: 0.4
  enabled: true
  # -- Specifies when Juice Shop instances will be deleted when unused for that period.
  gracePeriod: 2d
  # -- Specifies if the clean up job should delete the outdated namespaces or just report them. Set to false to only report outdated namespaces.
  SHOULD_DELETE: false
  # -- Cron in which the clean up job is run. Defaults to once in a quarter. Change this if your grace period if shorter than 15 minutes. See "https://crontab.guru/#0,15,30,45_*_*_*_*" for more details.
  cron: "0,15,30,45 * * * *"
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 1
  resources:
    requests:
      memory: 256Mi
    limits:
      memory: 256Mi
  # -- Optional Configure kubernetes scheduling affinity for the wrongsecretsCleanup Job(see: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)
  affinity: {}
  # -- Optional Configure kubernetes toleration for the wrongsecretsCleanup Job (see: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
  tolerations: []
